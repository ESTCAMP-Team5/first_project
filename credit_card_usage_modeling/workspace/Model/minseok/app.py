# app.py
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
from lightgbm import LGBMRegressor
from xgboost import XGBRegressor
from sklearn.ensemble import VotingRegressor
from sklearn.model_selection import train_test_split
import plotly.graph_objects as go
from lightgbm import LGBMClassifier
from sklearn.preprocessing import LabelEncoder
# ë¡œì»¬ ëª¨ë“ˆ import
from data_repository import create_data_repository
from models import CoffeeSalesAnalyzer, BusinessInsightGenerator

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ìˆ˜ì›ì‹œ ì»¤í”¼ ì—…ì¢… ë§¤ì¶œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸",
    page_icon="â˜•",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: white;
        text-align: center;
        padding: 1rem;
        background: linear-gradient(90deg, #2C3E50, #34495E);
        border-radius: 10px;
        margin-bottom: 2rem;
    }

    .sub-header {
        font-size: 1.2rem;
        color: #7F8C8D;
        text-align: center;
        margin-bottom: 2rem;
    }

    .insight-card {
        background-color: #1E1E1E;
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #333;
        margin-bottom: 1rem;
    }

    .metric-card {
        background-color: #2C3E50;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #34495E;
        text-align: center;
    }
</style>
""", unsafe_allow_html=True)


@st.cache_data
def load_data(repo_type: str = "mock"):
    """ë°ì´í„° ë¡œë“œ ë° ìºì‹±"""
    repo = create_data_repository(repo_type)
    return repo.get_combined_data()


@st.cache_resource
def load_analyzer():
    """ë¶„ì„ê¸° ë¡œë“œ ë° ìºì‹±"""
    return CoffeeSalesAnalyzer()


def main():
    # í—¤ë”
    st.markdown('<h1 class="main-header">â˜• ìˆ˜ì›ì‹œ ì»¤í”¼ ì—…ì¢… ë§¤ì¶œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ìš”ì¸</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">ì—¬ëŸ¬ ì™¸ë¶€ ìš”ì¸ë“¤ì— ì˜í•´ ì»¤í”¼ ë§¤ì¶œì— ì–´ë– í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ë¶„ì„ ë° ì˜ˆì¸¡</p>',
                unsafe_allow_html=True)

    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ Settings")

        # ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ
        data_source = st.selectbox(
            "Data Source",
            ["mock", "sqlite"],
            help="Choose your data source"
        )

        # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
        st.subheader("ğŸ“… Date Range")
        date_range = st.date_input(
            "Select date range",
            value=(datetime(2024, 1, 1), datetime(2024, 3, 31)),
            help="Choose the analysis period"
        )

        # ë¶„ì„ ì˜µì…˜
        st.subheader("ğŸ“Š Analysis Options")
        show_insights = st.checkbox("Show Business Insights", value=True)
        show_forecast = st.checkbox("Show Forecast", value=True)
        forecast_days = st.slider("Forecast Days", 1, 14, 7)

    try:
        # ë°ì´í„° ë¡œë“œ
        with st.spinner("Loading data..."):
            data = load_data(data_source)

            # ë‚ ì§œ í•„í„°ë§
            if len(date_range) == 2:
                start_date, end_date = date_range
                data = data[
                    (data['date'].dt.date >= start_date) &
                    (data['date'].dt.date <= end_date)
                    ]

        # ë¶„ì„ê¸° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ
        with st.spinner("Training models..."):
            analyzer = load_analyzer()
            analyzer.fit_models(data)

        # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
        display_main_dashboard(data, analyzer)

        # ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸
        if show_insights:
            display_business_insights(data, analyzer)

        # ì˜ˆì¸¡ ì„¹ì…˜
        if show_forecast:
            display_forecast_section(data, analyzer, forecast_days)

    except Exception as e:
        st.error(f"Error loading data: {str(e)}")
        st.info("Please check your data source configuration.")


def display_main_dashboard(data: pd.DataFrame, analyzer: CoffeeSalesAnalyzer):
    """ë©”ì¸ ëŒ€ì‹œë³´ë“œ í‘œì‹œ"""

    # ì²« ë²ˆì§¸ í–‰: ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°, ì‚°ì ë„, ë©”íŠ¸ë¦­
    col1, col2 = st.columns([2, 2])

    with col1:
        st.subheader("í‰ê·  ê¸°ì˜¨ì— ë”°ë¥¸ ì˜ˆì¸¡ ë§¤ì¶œ")

        # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        df = pd.read_csv('C:/Users/user-pc/Desktop/ìˆ˜ì›ì‹œ 24.3~25.3/df_coffee_ê¶Œì„ êµ¬.csv')
        df = df.drop(columns=['Unnamed: 0'])
        df = df.dropna()
        df_encoded = pd.get_dummies(df, columns=['sex']).astype(float)
        df_encoded['ta_ymd'] = pd.to_datetime(df_encoded['ta_ymd'])

        # ê³ ê° ê¸°ì¤€ ëˆ„ì  ì§€í‘œ ê³„ì‚°
        df_encoded = df_encoded.sort_values(by=['sex_F','sex_M', 'age', 'ta_ymd'])
        df_encoded['past_7day_amt'] = df_encoded.groupby(['sex_F','sex_M', 'age'])['amt'].transform(lambda x: x.rolling(window=7, min_periods=1).sum())
        df_encoded['past_30day_cnt'] = df_encoded.groupby(['sex_F','sex_M', 'age'])['cnt'].transform(lambda x: x.rolling(window=30, min_periods=1).sum())
        df_encoded['mean_amt_per_visit'] = df_encoded['amt'] / (df_encoded['cnt'] + 1e-5)

        # í”¼ì²˜/íƒ€ê²Ÿ ì„¤ì •
        features_amt = ['sex_F','sex_M', 'age', 'hour', 'day',
                        'past_7day_amt', 'past_30day_cnt', 'mean_amt_per_visit', 'AvgTemp', 'cty_rgn_no']
        X = df_encoded[features_amt]
        y_amt = df_encoded['amt']
        X_amt_train, X_amt_test, y_amt_train, y_amt_test = train_test_split(X, y_amt, test_size=0.2, random_state=42)

        # ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë°˜ ëª¨ë¸
        best_params_LGBM = {
            'num_leaves': 89, 'max_depth': 15, 'learning_rate': 0.0837, 'n_estimators': 859,
            'min_child_samples': 84, 'subsample': 0.9619, 'colsample_bytree': 0.7480,
            'reg_alpha': 3.8135, 'reg_lambda': 1.5787
        }

        best_params_XGBoost = {
            'n_estimators': 645, 'max_depth': 14, 'learning_rate': 0.03498956134885634,
            'subsample': 0.7132225654522615, 'colsample_bytree': 0.8050397258381967,
            'gamma': 0.3573772428817774, 'reg_alpha': 3.562730391807268, 'reg_lambda': 0.511245824338082
        }

        model_lgbm = LGBMRegressor(**best_params_LGBM)
        model_xgb = XGBRegressor(**best_params_XGBoost)

        # ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
        temp_model = VotingRegressor(estimators=[
            ('LGBM', model_lgbm),
            ('XGB', model_xgb)
        ], weights=[0.2, 0.8])
        temp_model.fit(X_amt_train, y_amt_train)
        y_pred_temp_amt = temp_model.predict(X_amt_test)

        # ê¸°ì˜¨ë³„ í‰ê·  ì˜ˆì¸¡ ë§¤ì¶œ ê³„ì‚° ë° ì‹œê°í™”
        X_amt_test_copy = X_amt_test.copy()
        X_amt_test_copy['predicted_amt'] = y_pred_temp_amt
        mean_amt_by_temp = X_amt_test_copy.groupby('AvgTemp')['predicted_amt'].mean()

        fig = go.Figure()

        fig.add_trace(go.Bar(
        x=mean_amt_by_temp.index,
        y=mean_amt_by_temp.values,
        text=[f"{int(y):,}ì›" for y in mean_amt_by_temp.values],
        textposition='outside',
        marker_color='lightcoral',
        name='ì˜ˆì¸¡ ë§¤ì¶œ'
        ))

        fig.update_layout(
        title='í‰ê·  ê¸°ì˜¨ë³„ í‰ê·  ì˜ˆì¸¡ ë§¤ì¶œ',
        xaxis=dict(title='í‰ê·  ê¸°ì˜¨ (â„ƒ)', range=[-1, 30]),
        yaxis=dict(title='ì˜ˆì¸¡ ë§¤ì¶œ'),
        showlegend=False,
        bargap=0.15,
        height=500
        )

        st.plotly_chart(fig, use_container_width=True)

        # ìµœì  ê¸°ì˜¨ í‘œì‹œ
        max_temp = mean_amt_by_temp.idxmax()
        max_amt = mean_amt_by_temp.max()
        st.markdown(f"ğŸŒ¡ï¸ **ê¸°ì˜¨ì´ {max_temp:.1f}â„ƒì¼ ë•Œ ì˜ˆì¸¡ ë§¤ì¶œì´ ê°€ì¥ ë†’ìŠµë‹ˆë‹¤: ì•½ {max_amt:,.0f}ì›**")

    with col2:
        st.subheader("ì‹œê°„ëŒ€ì— ë”°ë¥¸ ì˜ˆì¸¡ ë§¤ì¶œ")

        # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        df = pd.read_csv('C:/Users/user-pc/Desktop/ìˆ˜ì›ì‹œ 24.3~25.3/df_coffee_ê¶Œì„ êµ¬.csv')
        df = df.drop(columns=['Unnamed: 0'])
        df = df.dropna()
        df_encoded = pd.get_dummies(df, columns=['sex']).astype(float)
        df_encoded['ta_ymd'] = pd.to_datetime(df_encoded['ta_ymd'])

        # ê³ ê° ê¸°ì¤€ ëˆ„ì  ì§€í‘œ ê³„ì‚°
        df_encoded = df_encoded.sort_values(by=['sex_F','sex_M', 'age', 'ta_ymd'])
        df_encoded['past_7day_amt'] = df_encoded.groupby(['sex_F','sex_M', 'age'])['amt'].transform(lambda x: x.rolling(window=7, min_periods=1).sum())
        df_encoded['past_30day_cnt'] = df_encoded.groupby(['sex_F','sex_M', 'age'])['cnt'].transform(lambda x: x.rolling(window=30, min_periods=1).sum())
        df_encoded['mean_amt_per_visit'] = df_encoded['amt'] / (df_encoded['cnt'] + 1e-5)

        # í”¼ì²˜/íƒ€ê²Ÿ ì„¤ì •
        features_amt = ['sex_F','sex_M', 'age', 'hour', 'day',
                        'past_7day_amt', 'past_30day_cnt', 'mean_amt_per_visit', 'AvgTemp', 'cty_rgn_no']
        X = df_encoded[features_amt]
        y_amt = df_encoded['amt']
        X_amt_train, X_amt_test, y_amt_train, y_amt_test = train_test_split(X, y_amt, test_size=0.2, random_state=42)

        # ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë°˜ ëª¨ë¸
        best_params_LGBM = {
            'num_leaves': 89, 'max_depth': 15, 'learning_rate': 0.0837, 'n_estimators': 859,
            'min_child_samples': 84, 'subsample': 0.9619, 'colsample_bytree': 0.7480,
            'reg_alpha': 3.8135, 'reg_lambda': 1.5787
        }

        best_params_XGBoost = {
            'n_estimators': 645, 'max_depth': 14, 'learning_rate': 0.03498956134885634,
            'subsample': 0.7132225654522615, 'colsample_bytree': 0.8050397258381967,
            'gamma': 0.3573772428817774, 'reg_alpha': 3.562730391807268, 'reg_lambda': 0.511245824338082
        }

        model_lgbm = LGBMRegressor(**best_params_LGBM)
        model_xgb = XGBRegressor(**best_params_XGBoost)

        # ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
        hour_model = VotingRegressor(estimators=[
            ('LGBM', model_lgbm),
            ('XGB', model_xgb)
        ], weights=[0.2, 0.8])
        hour_model.fit(X_amt_train, y_amt_train)
        y_pred_hour_amt = hour_model.predict(X_amt_test)

        # ê¸°ì˜¨ë³„ í‰ê·  ì˜ˆì¸¡ ë§¤ì¶œ ê³„ì‚° ë° ì‹œê°í™”
        X_amt_test_copy = X_amt_test.copy()
        X_amt_test_copy['predicted_amt'] = y_pred_hour_amt
        mean_amt_by_hour = X_amt_test_copy.groupby('hour')['predicted_amt'].mean()

        # fig, ax = plt.subplots(figsize=(10, 6))
        # sns.barplot(x=mean_amt_by_hour.index.astype(int), y=mean_amt_by_hour.values, ax=ax)
        # ax.set_title("ì‹œê°„ëŒ€ë³„ í‰ê·  ì˜ˆì¸¡ ë§¤ì¶œ")
        # ax.set_xlabel("ì‹œê°„ëŒ€ (ë‹¨ìœ„ ì˜ˆ: 1=2ì‹œê°„24ë¶„ì”©)")
        # ax.set_ylabel("ì˜ˆì¸¡ ë§¤ì¶œ")
        # for x, y in zip(mean_amt_by_hour.index.astype(int), mean_amt_by_hour.values):
        #     rounded_y = round(int(y),-2)
        #     ax.text(x-1, y+1500, f'{rounded_y:,}\\', ha='center', fontsize=9)
        
        # st.pyplot(fig)
        # st.text("ì˜¤í›„ 12:00 ~ 14:24ì— ë§¤ì¶œì´ {:,}ì›ìœ¼ë¡œ ê°€ì¥ ë†’ì•˜ë‹¤.".format(round(int(mean_amt_by_hour.values.max()),-2)))
        fig = go.Figure()

        fig.add_trace(go.Bar(
            x=mean_amt_by_hour.index.astype(int),
            y=mean_amt_by_hour.values,
            text=[f"{round(int(y), -2):,}ì›" for y in mean_amt_by_hour.values],
            textposition='outside',
            marker_color='skyblue',
            name='ì˜ˆì¸¡ ë§¤ì¶œ'
            ))

        fig.update_layout(
        title='ì‹œê°„ëŒ€ë³„ í‰ê·  ì˜ˆì¸¡ ë§¤ì¶œ',
        xaxis=dict(
        title='ì‹œê°„ëŒ€ (ë‹¨ìœ„ ì˜ˆ: 1=2ì‹œê°„24ë¶„ì”©)',
        tickmode='linear',
        dtick=1
        ),
        yaxis=dict(title='ì˜ˆì¸¡ ë§¤ì¶œ'),
        showlegend=False,
        bargap=0.2,
        height=500
        )

        st.plotly_chart(fig, use_container_width=True)

        # ìµœê³  ë§¤ì¶œ ì‹œê°„ ì¶œë ¥
        peak_hour = mean_amt_by_hour.idxmax()
        peak_value = round(int(mean_amt_by_hour.max()), -2)
        st.markdown(f"â± 12:00 ~ 14:24ì— ë§¤ì¶œì´ {peak_value:,}ì›ìœ¼ë¡œ ê°€ì¥ ë†’ì•˜ë‹¤.")

    # ë‘ ë²ˆì§¸ í–‰: ì‹œê³„ì—´, íˆíŠ¸ë§µ
    st.markdown("---")
    col4, col5 = st.columns([1, 1])
    
    with col4:
        # features_amt = ['amt', 'cnt', 'age', 'AvgTemp', 'hour', 'day', 
        #         'cty_rgn_no']

        # # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
        # df = pd.read_csv('C:/Users/user-pc/Desktop/ìˆ˜ì›ì‹œ 24.3~25.3/df_coffee_ê¶Œì„ êµ¬.csv')
        # df = df.drop(columns=['Unnamed: 0'])
        # df = df.dropna()
        # df_encoded = pd.get_dummies(df, columns=['sex']).astype(float)
        # df_encoded = df_encoded.sort_values(by=['sex_F','sex_M', 'age', 'ta_ymd'])
        # df_encoded['past_7day_amt'] = df_encoded.groupby(['sex_F','sex_M', 'age'])['amt'].transform(lambda x: x.rolling(window=7, min_periods=1).sum())
        # df_encoded['past_30day_cnt'] = df_encoded.groupby(['sex_F','sex_M', 'age'])['cnt'].transform(lambda x: x.rolling(window=30, min_periods=1).sum())
        # df_encoded['mean_amt_per_visit'] = df_encoded['amt'] / (df_encoded['cnt'] + 1e-5)

        # X = df_encoded[features_amt]
        # y = LabelEncoder().fit_transform(df_encoded['sex_F'])

        # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        # sex_model = LGBMClassifier()
        # sex_model.fit(X_train, y_train)

        # # Streamlit UI
        # st.subheader("ğŸ§ ê³ ê° ì •ë³´ ê¸°ë°˜ ì„±ë³„ ì˜ˆì¸¡")

        # st.markdown("ğŸ’¡ ì•„ë˜ ìˆ˜ì¹˜ë¥¼ ì…ë ¥í•˜ë©´ ê³ ê°ì˜ ì„±ë³„ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

        # st.markdown("amt : ë§¤ì¶œê¸ˆì•¡, cnt : êµ¬ë§¤íšŸìˆ˜, age : ì—°ë ¹ëŒ€(1 ~ 9), AvgTemp : í‰ê·  ê¸°ì˜¨ \n" \
        # "\nhour : ì‹œê°„ëŒ€(1 ~ 10), day : ìš”ì¼(1 ~ 7), cty_rgn_no : í–‰ì •êµ¬ì½”ë“œ \n" \
        # "\n41111 : ì¥ì•ˆêµ¬ 41113 : ê¶Œì„ êµ¬ 41115 : íŒ”ë‹¬êµ¬ 41117 : ì˜í†µêµ¬")

        # # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
        # if 'inputs' not in st.session_state:
        #     st.session_state.inputs = {}
        # for feature in features_amt:
        #     if feature == "cty_rgn_no":
        #         st.session_state.inputs[feature] = st.selectbox("cty_rgn_no (í–‰ì •êµ¬ì—­ ì½”ë“œ ì„ íƒ)", [41111, 41113, 41115, 41117])
        #     elif feature == "AvgTemp":
        #         st.session_state.inputs[feature] = st.number_input("AvgTemp (í‰ê·  ê¸°ì˜¨)", value=15.0, step=0.1, format="%.1f")
        #     else:
        #         value = st.text_input(f"{feature} (ì •ìˆ˜ ì…ë ¥)", value=st.session_state.inputs.get(feature, ""))
        #     try:
        #         st.session_state.inputs[feature] = int(value)
        #     except ValueError:
        #         st.warning(f"â— '{feature}' ê°’ì€ ì •ìˆ˜ë¡œ ì…ë ¥ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
        #         st.stop()  # ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ì˜ˆì¸¡ê¹Œì§€ ê°€ì§€ ì•ŠìŒ

        # # ì˜ˆì¸¡ ë²„íŠ¼
        # if st.button("ì„±ë³„ ì˜ˆì¸¡í•˜ê¸°"):
        #     input_list = [st.session_state.inputs[feature] for feature in features_amt]
        #     input_array = np.array(input_list).reshape(1, -1)
        #     pred = sex_model.predict(input_array)[0]
        #     prob = sex_model.predict_proba(input_array)[0][1]

        #     result = "ì—¬ì ğŸ‘©" if pred == 1 else "ë‚¨ì ğŸ‘¨"
        #     st.success(f"ì˜ˆì¸¡ ì„±ë³„: **{result}**")
        #     st.metric("ì—¬ìì¼ í™•ë¥ ", f"{prob:.2%}")
        #     st.metric("ë‚¨ìì¼ í™•ë¥ ", f"{(1 - prob):.2%}")
        pass

    with col5:
        st.subheader("ğŸ—“ï¸ Monthly & Weekly Heatmap")
        fig_heatmap = analyzer.create_heatmap(data)
        st.plotly_chart(fig_heatmap, use_container_width=True)


def display_business_insights(data: pd.DataFrame, analyzer: CoffeeSalesAnalyzer):
    """ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ í‘œì‹œ"""

    st.markdown("---")
    st.header("ğŸ’¡ Business Insights")

    # ì¸ì‚¬ì´íŠ¸ ìƒì„±
    insights = BusinessInsightGenerator.generate_insights(data, analyzer)

    # ìš”ì•½ í†µê³„
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric(
            "Avg Daily Sales",
            f"{insights['summary']['avg_daily_sales']:,}",
            help="Average daily transactions"
        )

    with col2:
        st.metric(
            "Peak Sales",
            f"{insights['summary']['peak_sales']['sales']:,}",
            help=f"Peak sales on {insights['summary']['peak_sales']['date']}"
        )

    with col3:
        st.metric(
            "Temperature Correlation",
            f"{insights['temperature_insights']['correlation_coefficient']:.3f}",
            help=f"{insights['temperature_insights']['correlation_strength']} correlation"
        )

    with col4:
        weekend_premium = insights['time_insights']['weekend_vs_weekday']['weekend_premium']
        st.metric(
            "Weekend Premium",
            f"{weekend_premium:+.1f}%",
            help="Weekend sales vs weekday sales"
        )

    # ìƒì„¸ ì¸ì‚¬ì´íŠ¸
    col5, col6 = st.columns(2)

    with col5:
        st.subheader("ğŸŒ¡ï¸ Temperature Insights")
        st.markdown(f"""
        <div class="insight-card">
        <strong>Correlation Strength:</strong> {insights['temperature_insights']['correlation_strength']}<br>
        <strong>Optimal Temperature Range:</strong> {insights['temperature_insights']['optimal_temperature_range']['range']}<br>
        <strong>Avg Sales in Optimal Range:</strong> {insights['temperature_insights']['optimal_temperature_range']['avg_sales']:,}
        </div>
        """, unsafe_allow_html=True)

    with col6:
        st.subheader("ğŸ“… Time Pattern Insights")
        time_insights = insights['time_insights']
        st.markdown(f"""
        <div class="insight-card">
        <strong>Best Weekday:</strong> {time_insights['best_weekday']}<br>
        <strong>Worst Weekday:</strong> {time_insights['worst_weekday']}<br>
        <strong>Weekend Avg:</strong> {time_insights['weekend_vs_weekday']['weekend_avg']:,}<br>
        <strong>Weekday Avg:</strong> {time_insights['weekend_vs_weekday']['weekday_avg']:,}
        </div>
        """, unsafe_allow_html=True)

    # ê¶Œì¥ì‚¬í•­
    st.subheader("ğŸ¯ Marketing Recommendations")
    for i, recommendation in enumerate(insights['recommendations'], 1):
        st.markdown(f"{i}. {recommendation}")


def display_forecast_section(data: pd.DataFrame, analyzer: CoffeeSalesAnalyzer, forecast_days: int):
    """ì˜ˆì¸¡ ì„¹ì…˜ í‘œì‹œ"""

    st.markdown("---")
    st.header("ğŸ”® Sales Forecast")

    col1, col2 = st.columns([1, 1])

    with col1:
        st.subheader("ğŸ“ˆ Forecast Results")

        if analyzer.is_fitted:
            # ì˜ˆì¸¡ ìƒì„±
            forecast_df = analyzer.generate_forecast(data, forecast_days)

            # ì˜ˆì¸¡ ë°ì´í„° í‘œì‹œ
            display_forecast = forecast_df.copy()
            display_forecast['date'] = display_forecast['date'].dt.strftime('%Y-%m-%d')
            display_forecast['day_name'] = forecast_df['date'].dt.strftime('%A')

            st.dataframe(
                display_forecast[['date', 'day_name', 'predicted_temperature', 'predicted_sales']],
                use_container_width=True,
                hide_index=True,
                column_config={
                    'date': 'Date',
                    'day_name': 'Day',
                    'predicted_temperature': st.column_config.NumberColumn(
                        'Temp (Â°C)', format="%.1f"
                    ),
                    'predicted_sales': st.column_config.NumberColumn(
                        'Predicted Sales', format="%d"
                    )
                }
            )

            # ì˜ˆì¸¡ ìš”ì•½
            total_predicted = forecast_df['predicted_sales'].sum()
            avg_predicted = forecast_df['predicted_sales'].mean()

            st.metric("Total Predicted Sales", f"{total_predicted:,}")
            st.metric("Avg Daily Predicted Sales", f"{avg_predicted:.0f}")

        else:
            st.warning("Model not fitted. Please check your data.")

    with col2:
        st.subheader("ğŸ¯ Manual Prediction")

        # ìˆ˜ë™ ì˜ˆì¸¡ ì…ë ¥
        st.write("Enter conditions for custom prediction:")

        pred_temp = st.slider("Temperature (Â°C)", -5.0, 35.0, 15.0, 0.1)
        pred_day = st.selectbox("Day of Week",
                                ['Monday', 'Tuesday', 'Wednesday', 'Thursday',
                                 'Friday', 'Saturday', 'Sunday'])
        pred_month = st.selectbox("Month",
                                  ['January', 'February', 'March', 'April', 'May', 'June',
                                   'July', 'August', 'September', 'October', 'November', 'December'])

        day_mapping = {'Monday': 0, 'Tuesday': 1, 'Wednesday': 2, 'Thursday': 3,
                       'Friday': 4, 'Saturday': 5, 'Sunday': 6}
        month_mapping = {month: i + 1 for i, month in enumerate(['January', 'February', 'March', 'April', 'May', 'June',
                                                                 'July', 'August', 'September', 'October', 'November',
                                                                 'December'])}

        if st.button("Predict Sales", type="primary"):
            if analyzer.is_fitted:
                day_num = day_mapping[pred_day]
                month_num = month_mapping[pred_month]
                is_weekend = day_num >= 5

                prediction = analyzer.predict_sales(pred_temp, day_num, month_num, is_weekend)

                st.success(f"Predicted Sales: **{prediction['ensemble_prediction']:,}** transactions")

                # ëª¨ë¸ë³„ ì˜ˆì¸¡ ë¹„êµ
                st.write("**Model Comparison:**")
                st.write(f"- Linear Model: {prediction['linear_prediction']:,}")
                st.write(f"- Random Forest: {prediction['random_forest_prediction']:,}")
                st.write(f"- Ensemble: {prediction['ensemble_prediction']:,}")
            else:
                st.error("Model not fitted!")


def display_detailed_data_view(data: pd.DataFrame):
    """ìƒì„¸ ë°ì´í„° ë·° í‘œì‹œ"""

    st.markdown("---")
    st.subheader("ğŸ“‹ Detailed Data View")

    # í•„í„°ë§ ì˜µì…˜
    col_filter1, col_filter2 = st.columns(2)

    with col_filter1:
        temp_range = st.slider(
            "Temperature Range (Â°C)",
            min_value=float(data['avg_temperature'].min()),
            max_value=float(data['avg_temperature'].max()),
            value=(float(data['avg_temperature'].min()), float(data['avg_temperature'].max())),
            step=0.1
        )

    with col_filter2:
        transaction_range = st.slider(
            "Transaction Range",
            min_value=int(data['transaction_count'].min()),
            max_value=int(data['transaction_count'].max()),
            value=(int(data['transaction_count'].min()), int(data['transaction_count'].max())),
            step=100
        )

    # í•„í„°ë§ëœ ë°ì´í„°
    filtered_data = data[
        (data['avg_temperature'] >= temp_range[0]) &
        (data['avg_temperature'] <= temp_range[1]) &
        (data['transaction_count'] >= transaction_range[0]) &
        (data['transaction_count'] <= transaction_range[1])
        ].copy()

    filtered_data['date'] = filtered_data['date'].dt.strftime('%Y-%m-%d')

    st.dataframe(
        filtered_data,
        use_container_width=True,
        hide_index=True
    )


if __name__ == "__main__":
    main()

    # ìƒì„¸ ë°ì´í„° ë·° (í•­ìƒ í‘œì‹œ)
    try:
        data = load_data("mock")
        display_detailed_data_view(data)
    except:
        pass

    # í‘¸í„°
    st.markdown("---")
    st.markdown(
        """
        <div style='text-align: center; color: #7F8C8D; font-size: 0.9rem;'>
        ğŸš€ Built with Streamlit | ğŸ“Š Modular Architecture with Repository Pattern
        </div>
        """,
        unsafe_allow_html=True
    )